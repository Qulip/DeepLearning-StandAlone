{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed4ef575",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, LeakyReLU, Dropout, Input\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import librosa\n",
    "import pandas as pd\n",
    "\n",
    "sr = 44100\n",
    "\n",
    "# gan에 입력되는 noise에 대한 dimension\n",
    "NOISE_DIM = 10 #잘 모르겠음...ㅎㅎ\n",
    "\n",
    "# adam optimizer 정의, learning_rate = 0.0002, beta_1로 줍니다.\n",
    "# Vanilla Gan과 DCGAN에서 이렇게 셋팅을 해주는데\n",
    "# 이렇게 해줘야 훨씬 학습을 잘합니다.\n",
    "#그렇다고 합니다..ㅎㅎ\n",
    "adam = Adam(lr=0.0002, beta_1=0.5)\n",
    "mfcc_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f40460e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foldername : 1 - 20 files\n",
      "Filename : Ryu1.wav\n",
      "Filename : Ryu10.wav\n",
      "Filename : Ryu11.wav\n",
      "Filename : Ryu12.wav\n",
      "Filename : Ryu13.wav\n",
      "Filename : Ryu14.wav\n",
      "Filename : Ryu15.wav\n",
      "Filename : Ryu16.wav\n",
      "Filename : Ryu17.wav\n",
      "Filename : Ryu18.wav\n",
      "Filename : Ryu19.wav\n",
      "Filename : Ryu2.wav\n",
      "Filename : Ryu20.wav\n",
      "Filename : Ryu3.wav\n",
      "Filename : Ryu4.wav\n",
      "Filename : Ryu5.wav\n",
      "Filename : Ryu6.wav\n",
      "Filename : Ryu7.wav\n",
      "Filename : Ryu8.wav\n",
      "Filename : Ryu9.wav\n",
      "X_data : (14956, 45)\n",
      "(14956, 45)\n"
     ]
    }
   ],
   "source": [
    "def load_wave_generator(path): #이전 깃헙에서 가져온 파일 읽어들이는 함수(라벨 붙이는것만 삭제)\n",
    "\n",
    "    batch_waves = []\n",
    "    X_data = []\n",
    "    temp = []\n",
    "    global mfcc_data\n",
    "\n",
    "    folders = os.listdir(path)\n",
    "\n",
    "    for folder in folders:\n",
    "        if not os.path.isdir(path):continue #폴더가 아니면 continue\n",
    "        files = os.listdir(path+\"/\"+folder)\n",
    "        print(\"Foldername :\",folder,\"-\",len(files),\"files\")\n",
    "        #폴더 이름과 그 폴더에 속하는 파일 갯수 출력\n",
    "        for wav in files:\n",
    "            if not wav.endswith(\".wav\"):continue\n",
    "            else:\n",
    "                print(\"Filename :\",wav)#.wav 파일이 아니면 continue\n",
    "                y, sr = librosa.load(path+\"/\"+folder+\"/\"+wav)\n",
    "                mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=45, hop_length=int(sr*0.01),n_fft=int(sr*0.02)).T\n",
    "\n",
    "                X_data.extend(mfcc)\n",
    "                #print(\"MFCC Size : \", len(mfcc))\n",
    "    #end loop\n",
    "    print(\"X_data :\",np.shape(X_data))\n",
    "    mfcc_data = X_data\n",
    "    \n",
    "\n",
    "load_wave_generator(\"./data\")    #일단 RYU 음성 읽어오기\n",
    "print(np.shape(mfcc_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "759ceda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(data):\n",
    "    a = []\n",
    "    for j, row in enumerate(data):\n",
    "        if(j+500 == len(data)):\n",
    "            a = np.array(a)\n",
    "            return a\n",
    "        a.append(data[j:j+500])\n",
    "\n",
    "X_train = make_data(mfcc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a302393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14456, 500, 45)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a8723b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14456, 22500)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(22500,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(14456,22500)\n",
    "print(X_train.shape)\n",
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abda7509",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Sequential([                 #generator 시퀀스 생성 \n",
    "    Dense(256, input_dim=NOISE_DIM), \n",
    "    LeakyReLU(0.2), \n",
    "    Dense(512), \n",
    "    LeakyReLU(0.2), \n",
    "    Dense(1024), \n",
    "    LeakyReLU(0.2), \n",
    "    Dense(22500, activation='tanh'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3213dce9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 256)               2816      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 22500)             23062500  \n",
      "=================================================================\n",
      "Total params: 23,722,212\n",
      "Trainable params: 23,722,212\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28884e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Sequential([\n",
    "    Dense(1024, input_shape=(22500,), kernel_initializer=RandomNormal(stddev=0.02)),\n",
    "    LeakyReLU(0.2), #relu의 개선버전\n",
    "    Dropout(0.3), \n",
    "    Dense(512),\n",
    "    LeakyReLU(0.2), \n",
    "    Dropout(0.3), \n",
    "    Dense(256),\n",
    "    LeakyReLU(0.2), \n",
    "    Dropout(0.3), \n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5102a073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 1024)              23041024  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               524800    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 23,697,409\n",
      "Trainable params: 23,697,409\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3fe0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "429e732b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator는 학습을 하지 않도록 하며, Gan 모델에서는 generator만 학습하도록 합니다.\n",
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(NOISE_DIM,))\n",
    "x = generator(inputs=gan_input)\n",
    "output = discriminator(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "287b2f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 10)]              0         \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 22500)             23722212  \n",
      "_________________________________________________________________\n",
      "sequential_1 (Sequential)    (None, 1)                 23697409  \n",
      "=================================================================\n",
      "Total params: 47,419,621\n",
      "Trainable params: 23,722,212\n",
      "Non-trainable params: 23,697,409\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gan = Model(gan_input, output)\n",
    "gan.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dce7ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan.compile(loss='binary_crossentropy', optimizer=adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4b990ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_training(epoch, d_losses, g_losses):\n",
    "    # 오차에 대한 시각화\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.plot(g_losses, label='Generatror Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    print('epoch: {}, Discriminator Loss: {}, Generator Loss: {}'.format(epoch, np.asarray(d_losses).mean(), np.asarray(g_losses).mean()))\n",
    "    #오디오 파일 듣기 추가 요망"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc681491",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches(data, batch_size):\n",
    "    batches = []\n",
    "    for i in range(int(data.shape[0] // batch_size)):\n",
    "        batch = data[i * batch_size: (i + 1) * batch_size]\n",
    "        batches.append(batch)\n",
    "    return np.asarray(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "212dc7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator와 gan 모델의 loss 측정을 위한 list 입니다.\n",
    "d_losses = []\n",
    "g_losses = []\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS= 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5a83f7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, Discriminator Loss: 3.809654712677002, Generator Loss: 0.859234631061554\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-e90e26798dd3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[1;31m# Discriminator의 판별 학습을 방지합니다\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mdiscriminator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_gan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0md_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md_loss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[0;32m   1693\u001b[0m                                                     class_weight)\n\u001b[0;32m   1694\u001b[0m       \u001b[0mtrain_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1695\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1696\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1697\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    778\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 780\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    781\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    805\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    806\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 807\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    808\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    809\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2829\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2831\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1842\u001b[0m     \"\"\"\n\u001b[1;32m-> 1843\u001b[1;33m     return self._call_flat(\n\u001b[0m\u001b[0;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[0;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1922\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    # 각 배치별 학습\n",
    "    for real_sounds in get_batches(X_train, BATCH_SIZE):\n",
    "        # 랜덤 노이즈 생성\n",
    "        input_noise = np.random.uniform(-1, 1, size=[BATCH_SIZE, NOISE_DIM])\n",
    "        \n",
    "        # 가짜 이미지 데이터 생성\n",
    "        generated_sounds = generator.predict(input_noise)\n",
    "        \n",
    "        # Gan에 학습할 X 데이터 정의\n",
    "        x_dis = np.concatenate([real_sounds, generated_sounds])\n",
    "        \n",
    "        # Gan에 학습할 Y 데이터 정의\n",
    "        y_dis = np.zeros(2 * BATCH_SIZE)\n",
    "        y_dis[:BATCH_SIZE] = 0.9\n",
    "        \n",
    "        # Discriminator 훈련\n",
    "        discriminator.trainable = True\n",
    "        d_loss = discriminator.train_on_batch(x_dis, y_dis)\n",
    "        \n",
    "        # Gan 훈련\n",
    "        noise = np.random.uniform(-1, 1, size=[BATCH_SIZE, NOISE_DIM])\n",
    "        y_gan = np.ones(BATCH_SIZE)\n",
    "        \n",
    "        # Discriminator의 판별 학습을 방지합니다\n",
    "        discriminator.trainable = False\n",
    "        g_loss = gan.train_on_batch(noise, y_gan)\n",
    "        \n",
    "    d_losses.append(d_loss)\n",
    "    g_losses.append(g_loss)\n",
    "    \n",
    "    if epoch == 1 or epoch % 5 == 0:\n",
    "        visualize_training(epoch, d_losses, g_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab49847",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
